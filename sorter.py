# -*- coding: utf-8 -*-
import json
from collections import Counter
from os import path


# quick crude iteration over json generated by scrapy json
# counts video names, gets ones that were still working YT links and watched >5 times, matches URL, outputs json


# die if out.json does not exist
if not path.exists('out.json'):
    print('ERROR: watch-history file must be scraped, run "scrapy crawl parser -o out.json" first')
    exit(1)

# get scrapy json
with open('out.json') as file:
    data = json.load(file)

# counts video names
counter = Counter(video['name'][0] for video in data)

maybe_songs = {}

for key, value in counter.items():
    # arbitrary cutoff of >5 watches to be counted as a song
    if int(value) > 5:
        # video name is URL instead of actual name if the video got taken down, ignore these
        if not key.startswith("https://"):
            maybe_songs[key] = ""

# quick hacky URL retrieval for name
for name in maybe_songs:
    for entry in data:
        if entry['name'][0] == name:
            maybe_songs[name] = entry['url'][0]

# dumps json
with open('outmusic.json', 'w', encoding='utf-8') as file:
    json.dump(maybe_songs, file, ensure_ascii=False)
